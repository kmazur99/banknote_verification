{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a8f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148cc75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes = \"data_banknote_authentication.csv\"\n",
    "\n",
    "df = pd.read_csv(banknotes)\n",
    "features = df.values[:, :-1] # take first 4 columns(banknote features)\n",
    "labels = df.values[:, -1] # take last column(output either 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9491328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(values):\n",
    "    return 1 / (1 + np.exp(-values))\n",
    "\n",
    "def relu(values):\n",
    "    return np.maximum(0, values)\n",
    "\n",
    "def tanh(values):\n",
    "    return np.tanh(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dimensions, swarm with size 50, set of informants, random positions and velocity,\n",
    "# Run the ann once with the random particle weigth at first\n",
    "# Get the loss function of the forward pass and check against personal best for that particle\n",
    "# Set the new personal best for the particle if higher than original\n",
    "# Repat the steps for all particles in the swarm\n",
    "# Find-max on fitness to find global best\n",
    "# Update global best if higher than original\n",
    "# Update the position and velocity of each particle based on personal best, informant's best and global best\n",
    "# Repeat until target error is found or timeout\n",
    "\n",
    "# What we need\n",
    "\n",
    "# In the ann:\n",
    "# set_weigth method\n",
    "# Loss function\n",
    "\n",
    "# PSO:\n",
    "# Define particle class(position, velocity, best_position, best_fitness, fitness)\n",
    "# Define PSO class(num_particles, dimensions, num_iterations, target_error, cognitive_coefficient, social_coefficient, global_coefficient)\n",
    "# Define \"optimize\" method to iterate over each particle and update the values\n",
    "\n",
    "# A Link method\n",
    "# To trigger forward pass for current particle and get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee307b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layer\n",
    "class Layer:\n",
    "    def __init__(self, in_features, neurons, activation):\n",
    "        self.neurons = neurons # Number of neurons for this layer\n",
    "        self.weights = np.random.randn(in_features, self.neurons) # Calculate random weights between input and output neurons\n",
    "        self.biases = np.zeros(self.neurons) # Initialize bias for each neuron in this layer (currently 0)\n",
    "        self.activation = activation # activation function for this layer\n",
    "\n",
    "    # Forward pass through the layer\n",
    "    def forward_pass(self, in_data):\n",
    "        # Apply activation function to (weighted sum of inputs + biases)\n",
    "        output = self.activation(np.dot(in_data, self.weights) + self.biases)\n",
    "        return output # Output of current layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7113606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "class Network:\n",
    "    def __init__(self, in_features):\n",
    "        self.layers = [] # Store layers\n",
    "        self.in_features = in_features # Number of input features\n",
    "\n",
    "    # Add new layer to the neural network\n",
    "    def add(self, neurons, activation):\n",
    "        new_layer = Layer(self.in_features, neurons, activation) # initialize new layer\n",
    "        self.layers.append(new_layer) # add layer to list of layers\n",
    "        self.in_features = neurons # Update number of input features\n",
    "\n",
    "    # Forward pass through the entire neural network\n",
    "    def forward_pass(self, in_data):\n",
    "        output = in_data\n",
    "        # Iterate over all layers and apply forward passes\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward_pass(output)\n",
    "        return output # final output of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f7f6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Network(in_features=4) # specify number of input features\n",
    "\n",
    "# Add layers, specify number of neurons and activation function used\n",
    "ann.add(neurons=5, activation=relu)\n",
    "ann.add(neurons=6, activation=relu)\n",
    "ann.add(neurons=4, activation=relu)\n",
    "ann.add(neurons=1, activation=sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04883fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5390226112326769\n",
      "Correct: 739/1371\n"
     ]
    }
   ],
   "source": [
    "# Test neural network\n",
    "def test_ann(ann, features, labels):\n",
    "    predictions = ann.forward_pass(features)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Classify predicted values\n",
    "    for prediction in predictions:\n",
    "        if prediction > 0.5:\n",
    "            predicted_label = 1\n",
    "        else:\n",
    "            predicted_label = 0\n",
    "        \n",
    "        predicted_labels.append(predicted_label)\n",
    "    \n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        # print predictions\n",
    "# print(f\"Banknote {i}, Predicted label: {predicted_labels[i]}, Actual label: {int(labels[i])}\")\n",
    "        \n",
    "        # Add to correct count if prediction matches actual label\n",
    "        \n",
    "        if predicted_labels[i] == labels[i]:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    # Calculate and print accuracy\n",
    "    accuracy = (correct_predictions / len(labels))\n",
    "    print(f\"\\nAccuracy: {accuracy}\")\n",
    "    print(f\"Correct: {correct_predictions}/{len(labels)}\")\n",
    "\n",
    "test_ann(ann, features, labels)\n",
    "\n",
    "# Currently resutls are random as there is no learning and we are testing on random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889011d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
