{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f053500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 32]\n",
      "rows = 7043\n",
      "columns = 21\n",
      "Training time (Log Reg using Gradient descent):4.197920083999634 seconds\n",
      "Learning rate: 0.001\n",
      "Iteration: 20000\n",
      "Accuracy (Loss minimization):\n",
      "78.1769132471958\n",
      "Confusion Matrix: \n",
      "TP= 937\n",
      "TN= 4569\n",
      "FP= 605\n",
      "FN= 932\n",
      "Precision =  0.6076523994811932\n",
      "Recall =  0.5013376136971642\n",
      "F score = \n",
      "0.5493990032248608\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#shape[0] : number of rows\n",
    "#shape[1] : number of columns\n",
    "def sigmoid(X, weight):\n",
    "    z = np.dot(X, weight)\n",
    "   # print(\"Z dim =\", z.shape[0])\n",
    "   # print(\"z =\", z)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#print(1/(1+np.exp(-0.17)))\n",
    "\n",
    "#print(1+np.exp(1))\n",
    "#print(1 + np.exp([1]))\n",
    "#print(1 + np.exp([1,2]))\n",
    "print(np.dot([[1,2,3],[4,5,6]],[1,2,3]))\n",
    "\n",
    "def gradient_descent(X, h, y):\n",
    "#X.T transpose of X\n",
    "#y.shape[0] is sample size (m in the learning material), we divide by to find avg (batch mode)\n",
    "    return np.dot(X.T, (h - y)) / y.shape[0]\n",
    "\n",
    "def update_weight_loss(weight, learning_rate, gradient):\n",
    "    return weight - learning_rate * gradient\n",
    "\n",
    "data = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "print(\"rows = {}\".format(data.shape[0]))\n",
    "print(\"columns = {}\".format(data.shape[1]))\n",
    "pd.DataFrame(data.dtypes).rename(columns = {0:\"dtype\"})\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df['class'] = df['Churn'].apply(lambda x : 1 if x == \"Yes\" else 0)\n",
    "#df.shape[1]\n",
    "X = df[['tenure','MonthlyCharges']].copy()\n",
    "y = df['class'].copy()\n",
    "\n",
    "intercept = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((intercept, X), axis=1)\n",
    "#print(X.shape[0],X.shape[1])\n",
    "\n",
    "#alpha: learning rate\n",
    "alpha=0.001\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "num_iter = 20000\n",
    "# inputs\n",
    "theta = np.zeros(X.shape[1])\n",
    "for i in range(num_iter):\n",
    "    #print(\"X=\", X)\n",
    "    #print(\"X.T=\", X.T)\n",
    "    #print(\"Theta=\", theta)\n",
    "    h = sigmoid(X, theta)\n",
    "    #print(\"h=\", h)\n",
    "    #print(\"y=\", y)\n",
    "    gradient = gradient_descent(X, h, y)\n",
    "    #print(\"gradient =\", gradient)\n",
    "    theta = update_weight_loss(theta, alpha, gradient)\n",
    "\n",
    "print(\"Training time (Log Reg using Gradient descent):\" + str(time.time() - start_time) + \" seconds\")\n",
    "print(\"Learning rate: {}\\nIteration: {}\".format(alpha, num_iter))\n",
    "\n",
    "result = sigmoid(X, theta)\n",
    "\n",
    "f = pd.DataFrame(np.around(result, decimals=6)).join(y)\n",
    "f['pred'] = f[0].apply(lambda x : 0 if x < 0.5 else 1)\n",
    "print(\"Accuracy (Loss minimization):\")\n",
    "print(f.loc[f['pred']==f['class']].shape[0] / f.shape[0] * 100)\n",
    "\n",
    "#For Confusion Matrix\n",
    "YActual = f['class'].tolist()\n",
    "YPredicted =  f['pred'].tolist()\n",
    "\n",
    "#print(YActual)\n",
    "#print(YPredicted)\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for l1,l2 in zip(YActual, YPredicted):\n",
    "    if (l1 == 1 and  l2 == 1):\n",
    "        TP = TP + 1\n",
    "    elif (l1 == 0 and l2 == 0):\n",
    "        TN = TN + 1\n",
    "    elif (l1 == 1 and l2 == 0):\n",
    "        FN = FN + 1\n",
    "    elif (l1 == 0 and l2 == 1):\n",
    "        FP = FP + 1\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "\n",
    "print(\"TP=\", TP)\n",
    "print(\"TN=\", TN)\n",
    "print(\"FP=\", FP)\n",
    "print(\"FN=\", FN)\n",
    "\n",
    "# Precision = TruePositives / (TruePositives + FalsePositives)\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "\n",
    "\n",
    "P = TP/(TP + FP)\n",
    "R = TP/(TP + FN)\n",
    "\n",
    "print(\"Precision = \", P)\n",
    "print(\"Recall = \", R)\n",
    "\n",
    "#F-Measure = (2 * Precision * Recall) / (Precision + Recall), sometimes called F1\n",
    "\n",
    "F1 = (2* P * R)/(P + R)\n",
    "\n",
    "print(\"F score = \")\n",
    "print(F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb751f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
